{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44RgL_3YuEpT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install numpy pandas scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqLFbJtryBaf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KD6eipWS3r7X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These values are produced via Bayesian hyperparameter optimization in Azure\n",
    "# AutoML.\n",
    "models_parameters = {\n",
    "    \"colsample_bylevel\": [1, 1, 1, 1, 0.9, 1, 1, 1],\n",
    "    \"colsample_bytree\": [0.6, 0.5, 0.7, 0.7, 1, 0.8, 0.9, 0.5],\n",
    "    \"eta\": [0.3, 0.4, 0.4, 0.3, 0.2, 0.3, 0.3, 0.5],\n",
    "    \"gamma\": [1, 1, 0.1, 0, 0.01, 0, 0, 0],\n",
    "    \"learning_rate\": [0.3, 0.4, 0.4, 0.3, 0.2, 0.3, 0.3, 0.5],\n",
    "    \"max_depth\": [7, 9, 6, 10, 6, 9, 7, 9],\n",
    "    \"max_leaves\": [31, 127, 31, 31, 0, 7, 0, 3],\n",
    "    \"n_estimators\": [600, 600, 400, 800, 600, 400, 400, 400],\n",
    "    \"reg_alpha\": [0.2083, 0, 2.1875, 1.25, 2.2916, 0, 1.77083, 2.5],\n",
    "    \"reg_lambda\": [0.4167, 2.5, 1.25, 0.52083, 1.6667, 1.35417, 0.83, 0.3125],\n",
    "    \"subsample\": [1, 1, 1, 1, 1, 0.6, 0.9, 0.5],\n",
    "    \"tree_method\": [\"auto\", \"auto\", \"auto\", \"hist\", \"auto\", \"auto\", \"auto\", \"auto\"],\n",
    "    \"weights\": [2/11, 2/11, 2/11, 1/11, 1/11, 1/11, 1/11, 1/11]\n",
    "}\n",
    "\n",
    "def create_model(kwargs):\n",
    "  return XGBClassifier(\n",
    "      base_score=0.5,\n",
    "      importance_type='gain',\n",
    "      objective='multi:softprob',\n",
    "      random_state=42,\n",
    "      validate_parameters=1,\n",
    "      verbosity=3,\n",
    "      **kwargs\n",
    "  )\n",
    "\n",
    "def create_ensemble():\n",
    "  estimators = []\n",
    "\n",
    "  for i in range(8):\n",
    "    kwargs = {}\n",
    "\n",
    "    for key in models_parameters:\n",
    "      kwargs[key] = models_parameters[key][i]\n",
    "    \n",
    "    model = create_model(kwargs)\n",
    "    estimators.append((f\"model_{i}\", model))\n",
    "\n",
    "  return VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    flatten_transform=False,\n",
    "    verbose=True,\n",
    "    voting=\"soft\",\n",
    "    weights=models_parameters[\"weights\"]\n",
    "  )\n",
    "\n",
    "model = create_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NitytDmoDuiG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset Preprocessing\n",
    "\n",
    "X = pd.read_csv(\"train_values.csv\", index_col=\"building_id\")\n",
    "y = pd.read_csv(\"train_labels.csv\", index_col=\"building_id\")\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X,\n",
    "                                                                y,\n",
    "                                                                stratify=y,\n",
    "                                                                test_size=0.2)\n",
    "\n",
    "categorical_features = X.select_dtypes(include=object).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"categorical\", OneHotEncoder(), categorical_features),\n",
    "        (\"numerical\", StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_validation_preprocessed = preprocessor.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5aPIQCuEBZy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "model.fit(X_train_preprocessed, y_train.values.flatten())\n",
    "\n",
    "# Evaluate the model performance on the validation dataset.\n",
    "f1_score(y_validation.values.flatten(), model.predict(X_validation_preprocessed), average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ii3bkQRWt72Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create submission.\n",
    "\n",
    "X_test = pd.read_csv(\"test_values.csv\", index_col=\"building_id\")\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "predictions = model.predict(X_test_preprocessed)\n",
    "\n",
    "submission_format = pd.read_csv(\"submission_format.csv\", index_col='building_id')\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    data=predictions,\n",
    "    columns=submission_format.columns,\n",
    "    index=submission_format.index\n",
    ")\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
